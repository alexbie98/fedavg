{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FedAvg",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcvMbe-JowiY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# set random seeds\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "cuda = torch.device(\"cuda\")\n",
        "cpu = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# debug/utilities\n",
        "def view_10(x,y):\n",
        "    fig, axes = plt.subplots(2,5, figsize=(10,4))\n",
        "    for i,ax in enumerate(axes.flat):\n",
        "        ax.axis(\"off\")\n",
        "        ax.set_title(y[i].numpy())\n",
        "        ax.imshow(x[i][0], cmap=\"gray\")\n",
        "\n",
        "def num_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "wxnn8owMu4Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparams\n",
        "bsz = 10"
      ],
      "metadata": {
        "id": "ZoZbOl8Gt3GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "VixfemygHq3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_data = datasets.MNIST('./', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST('./', train=False, download = True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=False, batch_size=10); # unused, just for debugging\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=1000);\n",
        "\n",
        "# debug batch\n",
        "x_debug, y_debug = next(iter(test_loader))\n",
        "x_debug = x_debug[:10].to(cuda)\n",
        "y_debug = y_debug[:10].to(cuda)\n",
        "view_10(x_debug.cpu(), y_debug.cpu())"
      ],
      "metadata": {
        "id": "IfPfvy-7sf-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# partition the dataset into a dataloader for each client\n",
        "\n",
        "def iid_partition_loader(train_data, bsz):\n",
        "    client_train_data = torch.utils.data.random_split(train_data,[600 for x in range(100)])\n",
        "    client_train_loader = [torch.utils.data.DataLoader(x, batch_size = bsz, shuffle=True) for x in client_train_data]\n",
        "    return client_train_loader\n",
        "\n",
        "def noniid_partition_loader(train_data, bsz):\n",
        "\n",
        "    # load data into memory\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=1000);\n",
        "    train_data_loaded = [x for x in train_loader]\n",
        "    train_data_x = torch.cat([x[0] for x in train_data_loaded])\n",
        "    train_data_y = torch.cat([x[1] for x in train_data_loaded])\n",
        "\n",
        "    # sort\n",
        "    ind = torch.argsort(train_data_y)\n",
        "    train_data_x = train_data_x[ind]\n",
        "    train_data_y = train_data_y[ind]\n",
        "\n",
        "    #split into 200 shards of size 300\n",
        "    shards = [(train_data_x[300*i:300*(i+1)], train_data_y[300*i:300*(i+1)]) for i in range(200)]\n",
        "    random.shuffle(shards) # shuffle shards\n",
        "\n",
        "    # pick 2 shards to creat a dataset\n",
        "    client_train_data = [torch.utils.data.TensorDataset(torch.cat([shards[2*i][0], shards[2*i+1][0]]),\n",
        "                                                        torch.cat([shards[2*i][1], shards[2*i+1][1]])) for i in range(100)]\n",
        "\n",
        "    # make dataloaders\n",
        "    client_train_loader = [torch.utils.data.DataLoader(x, batch_size = bsz, shuffle=True) for x in client_train_data]\n",
        "    return client_train_loader"
      ],
      "metadata": {
        "id": "-7guxtDs3ZHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get client dataloaders\n",
        "\n",
        "iid_client_train_loader = iid_partition_loader(train_data, 10)\n",
        "noniid_client_train_loader = noniid_partition_loader(train_data, 10)"
      ],
      "metadata": {
        "id": "a4mN1wUr4izX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# non-iid\n",
        "label_dist = torch.zeros(10)\n",
        "for (x,y) in noniid_client_train_loader[25]:\n",
        "    label_dist+= torch.sum(F.one_hot(y,num_classes=10), dim=0)\n",
        "print(\"non-iid: \", label_dist)\n",
        "view_10(x,y)"
      ],
      "metadata": {
        "id": "fqZgr4FO41Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iid\n",
        "label_dist = torch.zeros(10)\n",
        "for (x,y) in iid_client_train_loader[25]:\n",
        "    label_dist+= torch.sum(F.one_hot(y, num_classes=10), dim=0)\n",
        "print(\"iid: \", label_dist)\n",
        "view_10(x,y)"
      ],
      "metadata": {
        "id": "ls_0Ke21Govu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "2cAwYqdeHvcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define fully connected NN\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 200);\n",
        "        self.fc2 = nn.Linear(200, 200);\n",
        "        self.out = nn.Linear(200, 10);\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.flatten(1) # [B x 784]\n",
        "        x = F.relu(self.fc1(x)) # [B x 200]\n",
        "        x = F.relu(self.fc2(x)) # [B x 200]\n",
        "        x = self.out(x) # [B x 10]\n",
        "        return x\n",
        "\n",
        "print(MLP())\n",
        "print(num_params(MLP()))"
      ],
      "metadata": {
        "id": "pnKxxiKYo4cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define cnn\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5) \n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.fc = nn.Linear(1024, 512)\n",
        "        self.out = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(self.conv1(x), 2, 2) # [B x 32 x 12 x 12]\n",
        "        x = F.max_pool2d(self.conv2(x), 2, 2) # [B x 64 x 4 x 4]\n",
        "        x = x.flatten(1) # [B x 1024]\n",
        "        x = F.relu(self.fc(x)) # [B x 512]\n",
        "        x = self.out(x) # [B x 10]\n",
        "        return x\n",
        "\n",
        "print(CNN())\n",
        "print(num_params(CNN()))"
      ],
      "metadata": {
        "id": "jefi6wlYpXYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "r6Tmim2lHz4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def validate(model):\n",
        "    model = model.to(cuda)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for (t, (x,y)) in enumerate(test_loader):\n",
        "            x = x.to(cuda)\n",
        "            y = y.to(cuda)\n",
        "            out = model(x)\n",
        "            correct += torch.sum(torch.argmax(out, dim=1) == y).item()\n",
        "            total += x.shape[0]\n",
        "    return correct/total"
      ],
      "metadata": {
        "id": "A4mTFWgx0gmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_client(id, client_loader, global_model, num_local_epochs, lr):\n",
        "    local_model = copy.deepcopy(global_model)\n",
        "    local_model = local_model.to(cuda)\n",
        "    local_model.train()\n",
        "    optimizer = torch.optim.SGD(local_model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(num_local_epochs):\n",
        "        for (i, (x,y)) in enumerate(client_loader):\n",
        "            x = x.to(cuda)\n",
        "            y = y.to(cuda)\n",
        "            optimizer.zero_grad()\n",
        "            out = local_model(x)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return local_model\n",
        "\n",
        "def running_model_avg(current, next, scale):\n",
        "    if current == None:\n",
        "        current = next\n",
        "        for key in current:\n",
        "            current[key] = current[key] * scale\n",
        "    else:\n",
        "        for key in current:\n",
        "            current[key] = current[key] + (next[key] * scale)\n",
        "    return current"
      ],
      "metadata": {
        "id": "-YDOK1S0H_Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fed_avg_experiment(global_model, num_clients_per_round, num_local_epochs, lr, client_train_loader, max_rounds, filename):\n",
        "    round_accuracy = []\n",
        "    for t in range(max_rounds):\n",
        "        print(\"starting round {}\".format(t))\n",
        "\n",
        "        # choose clients\n",
        "        clients = np.random.choice(np.arange(100), num_clients_per_round, replace = False)\n",
        "        print(\"clients: \", clients)\n",
        "\n",
        "        global_model.eval()\n",
        "        global_model = global_model.to(cpu)\n",
        "        running_avg = None\n",
        "\n",
        "        for i,c in enumerate(clients):\n",
        "            # train local client\n",
        "            print(\"round {}, starting client {}/{}, id: {}\".format(t, i+1,num_clients_per_round, c))\n",
        "            local_model = train_client(c, client_train_loader[c], global_model, num_local_epochs, lr)\n",
        "\n",
        "            # add local model parameters to running average\n",
        "            running_avg = running_model_avg(running_avg, local_model.state_dict(), 1/num_clients_per_round)\n",
        "        \n",
        "        # set global model parameters for the next step\n",
        "        global_model.load_state_dict(running_avg)\n",
        "\n",
        "        # validate\n",
        "        val_acc = validate(global_model)\n",
        "        print(\"round {}, validation acc: {}\".format(t, val_acc))\n",
        "        round_accuracy.append(val_acc)\n",
        "\n",
        "        if (t % 10 == 0):\n",
        "          np.save(filename+'_{}'.format(t)+'.npy', np.array(round_accuracy))\n",
        "\n",
        "    return np.array(round_accuracy)\n"
      ],
      "metadata": {
        "id": "pJgWgjM-Pv4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## MLP experiments"
      ],
      "metadata": {
        "id": "SrmY-TPnGI77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLP()\n",
        "print(mlp)\n",
        "print(\"total params: \", num_params(mlp))"
      ],
      "metadata": {
        "id": "Mwymk72xlaDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP - iid - m=10 experiment\n",
        "mlp_iid_m10 = copy.deepcopy(mlp)\n",
        "acc_mlp_iid_m10 = fed_avg_experiment(mlp_iid_m10, num_clients_per_round=10, \n",
        "                                 num_local_epochs=1,\n",
        "                                 lr=0.05,\n",
        "                                 client_train_loader = iid_client_train_loader,\n",
        "                                 max_rounds=100,\n",
        "                                 filename='./acc_mlp_iid_m10')\n",
        "print(acc_mlp_iid_m10)\n",
        "np.save('./acc_mlp_iid_m10.npy', acc_mlp_iid_m10)"
      ],
      "metadata": {
        "id": "SDjaFBJAjeHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP - iid - m=50 experiment\n",
        "mlp_iid_m50 = copy.deepcopy(mlp)\n",
        "acc_mlp_iid_m50 = fed_avg_experiment(mlp_iid_m50, num_clients_per_round=50, \n",
        "                                 num_local_epochs=1,\n",
        "                                 lr=0.05,\n",
        "                                 client_train_loader = iid_client_train_loader,\n",
        "                                 max_rounds=100,\n",
        "                                 filename='./acc_mlp_iid_m50')\n",
        "print(acc_mlp_iid_m50)\n",
        "np.save('./acc_mlp_iid_m50.npy', acc_mlp_iid_m50)"
      ],
      "metadata": {
        "id": "u5x4lhIcyyt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP - non-iid - m=10 experiment\n",
        "mlp_noniid_m10 = copy.deepcopy(mlp)\n",
        "acc_mlp_noniid_m10 = fed_avg_experiment(mlp_noniid_m10, num_clients_per_round=10, \n",
        "                                 num_local_epochs=1,\n",
        "                                 lr=0.05,\n",
        "                                 client_train_loader = noniid_client_train_loader,\n",
        "                                 max_rounds=300,\n",
        "                                 filename = './acc_mlp_noniid_m10')\n",
        "print(acc_mlp_noniid_m10)\n",
        "np.save('./acc_mlp_noniid_m10.npy', acc_mlp_noniid_m10)"
      ],
      "metadata": {
        "id": "O4NeL5U4zKDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP - noniid - m=50 experiment\n",
        "mlp_noniid_m50 = copy.deepcopy(mlp)\n",
        "acc_mlp_noniid_m50 = fed_avg_experiment(mlp_noniid_m50, num_clients_per_round=50, \n",
        "                                 num_local_epochs=1,\n",
        "                                 lr=0.05,\n",
        "                                 client_train_loader = noniid_client_train_loader,\n",
        "                                 max_rounds=300,\n",
        "                                 filename='./acc_mlp_noniid_m50')\n",
        "print(acc_mlp_noniid_m50)\n",
        "np.save('./acc_mlp_noniid_m50.npy', acc_mlp_noniid_m50)"
      ],
      "metadata": {
        "id": "O0MeL-jQzXd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Experiments"
      ],
      "metadata": {
        "id": "yR4UdghyGNCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = CNN()\n",
        "print(cnn)\n",
        "print(\"total params: \", num_params(cnn))"
      ],
      "metadata": {
        "id": "RQKqbwx6413q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN - iid - m=10 experiment\n",
        "cnn_iid_m10 = copy.deepcopy(cnn)\n",
        "acc_cnn_iid_m10 = fed_avg_experiment(cnn_iid_m10, num_clients_per_round=10, \n",
        "                                 num_local_epochs=5,\n",
        "                                 lr=0.01,\n",
        "                                 client_train_loader = iid_client_train_loader,\n",
        "                                 max_rounds=100,\n",
        "                                 filename='./acc_cnn_iid_m10')\n",
        "print(acc_cnn_iid_m10)\n",
        "np.save('./acc_cnn_iid_m10.npy', acc_cnn_iid_m10)"
      ],
      "metadata": {
        "id": "JEuqsiF3GkXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN - iid - m=50 experiment\n",
        "cnn_iid_m50 = copy.deepcopy(cnn)\n",
        "acc_cnn_iid_m50 = fed_avg_experiment(cnn_iid_m50, num_clients_per_round=50, \n",
        "                                 num_local_epochs=5,\n",
        "                                 lr=0.01,\n",
        "                                 client_train_loader = iid_client_train_loader,\n",
        "                                 max_rounds=100,\n",
        "                                 filename='./acc_cnn_iid_m50')\n",
        "print(acc_cnn_iid_m50)\n",
        "np.save('./acc_cnn_iid_m50.npy', acc_cnn_iid_m50)"
      ],
      "metadata": {
        "id": "-0Eo_EYbGTfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN - non-iid - m=10 experiment\n",
        "cnn_noniid_m10 = copy.deepcopy(cnn)\n",
        "acc_cnn_noniid_m10 = fed_avg_experiment(cnn_noniid_m10, num_clients_per_round=10, \n",
        "                                 num_local_epochs=5,\n",
        "                                 lr=0.01,\n",
        "                                 client_train_loader = noniid_client_train_loader,\n",
        "                                 max_rounds=200,\n",
        "                                 filename='./acc_cnn_noniid_m10')\n",
        "print(acc_cnn_noniid_m10)\n",
        "np.save('./acc_cnn_noniid_m10.npy', acc_cnn_noniid_m10)"
      ],
      "metadata": {
        "id": "-EUw04QbHN9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN - non-iid - m=50 experiment\n",
        "cnn_noniid_m50 = copy.deepcopy(cnn)\n",
        "acc_cnn_noniid_m50 = fed_avg_experiment(cnn_noniid_m50, num_clients_per_round=50, \n",
        "                                 num_local_epochs=5,\n",
        "                                 lr=0.01,\n",
        "                                 client_train_loader = noniid_client_train_loader,\n",
        "                                 max_rounds=100,\n",
        "                                 filename='./acc_cnn_noniid_m50')\n",
        "print(acc_cnn_noniid_m50)\n",
        "np.save('./acc_cnn_noniid_m50.npy', acc_cnn_noniid_m50)"
      ],
      "metadata": {
        "id": "gICkrXpMHdZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view_10(x_debug[:10].to(cpu), torch.argmax(model(x_debug),dim=1)[:10].to(cpu))\n",
        "\n",
        "# m = CNN().to(cuda)\n",
        "# m.train()\n",
        "# lr = 0.01\n",
        "# opt = torch.optim.SGD(m.parameters(), lr)\n",
        "\n",
        "# for epoch in range(5):\n",
        "#     for (t, (x,y)) in enumerate(train_loader):\n",
        "#         x = x.to(cuda)\n",
        "#         y = y.to(cuda)\n",
        "#         opt.zero_grad()\n",
        "#         out = m(x)\n",
        "#         loss = criterion(out, y)\n",
        "#         loss.backward()\n",
        "#         opt.step()\n",
        "\n",
        "#         if (t%100 == 0):\n",
        "#             print(\"epoch {}, step {}, loss: {}\".format(epoch, t, loss))\n",
        "\n",
        "#     print(\"running validation\")\n",
        "#     acc = validate(m)\n",
        "#     print(\"epoch {} validation acc: {}\".format(epoch, acc))"
      ],
      "metadata": {
        "id": "BZaLNsaS00jV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}